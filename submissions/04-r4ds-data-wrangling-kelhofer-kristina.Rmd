---
title: "Data Wrangling Exercises"
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = FALSE, message = FALSE)
```

The following six exercises are based on concepts covered in 
[Chapter 12][G&W 2017, 12] and [Chapter 13][G&W 2017, 13] of 
[R for Data Science][G&W 2017]. Use the `flights` and `who` datasets that come 
with the `nycflights13` and `tidyverse` packages to work on them, and start by 
loading the `tidyverse` and `nycflights13`.

```{r, echo = TRUE, eval = TRUE, warning = FALSE}
library(tidyverse)
library(nycflights13)
?flights
?who
```

Also, run `?flights` and `?who` in the console to (re)familiarize yourself with
these datasets.


--- 

## Exercise 1
```{r, echo = TRUE, eval = TRUE, error = TRUE}
people <- tribble(
  ~name,            ~key,     ~value,
  #---------------/---------/--------
  "Ousmane Diaby",    "age",      23,
  "Ousmane Diaby", "height",     196,
  "Ousmane Diaby",    "age",      33,
  "Rich Eldh",        "age",      23,
  "Rich Eldh",     "height",     195
)

people %>% 
  spread(key, value)
```

Why can't you spread `people`? How could you add a new column to `people` to fix
the problem?

***Exercise 1 Solution***
```{r, echo = TRUE, eval = TRUE, warning = FALSE}
people %>% 
  group_by(key) %>% 
  mutate(time = row_number()) %>% 
  spread(key, value)
```

**Hint:** You can use `group_by()` and `row_number()` to create a `time` column
that uniquely identifies time periods in `people`. This `time` column will fix
the problem.

**Note:** This question is based on [12.3.3 #3][G&W 2017, 12.3.3]. It is
designed to help you hone your understanding of how 
[`spread()`][G&W 2017, 12.3.2] behaves with non-unique rows.

---

## Exercise 2
```{r, echo = TRUE}
preg <- tribble(
  ~pregnant, ~male, ~female,
  #--------/------/---------
  "yes",        NA,      10,
  "no",         20,      12
)
```

Do you need to [gather][G&W 2017, 12.3.1] or [spread][G&W 2017, 12.3.2] `preg`
to tidy it? What variables are there in `preg`?

***Exercise 2 Solution***
-You would want to gather `preg` to tidy it
-Numeric variables, likely for how many weeks along or age
```{r, echo = TRUE, warning = FALSE}

preg %>% 
  gather(`male`, `female`, key = gender, value = count)

```

**Note:** This question is based on [12.3.3 #4][G&W 2017, 12.3.3].

---

## Exercise 3
```{r, echo = TRUE, eval = TRUE, warning = TRUE}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"))
```

How would you explain this warning message in layman's terms to someone who
couldn't figure out what it means? Suppose they want to make sure that every
piece of the tibble makes its way into the result of the 
[`separate()`][G&W 2017, 12.4.1] function call. What could they do to remedy the
situation?

***Exercise 3 Solution***
The function was told to separate into 3 columns, but was given 4 letters in row 2, so it decided to get rid of the last letter, 'g'. To fix this you could add a fourth column into the code, as shown in this solution to exercise 3.
```{r, echo = TRUE, eval = TRUE, warning = FALSE}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three", "four"))
```


**Note:** This question is based on [12.4.3 #1][G&W 2017, 12.4.3]. It is
designed to strengthen your ability to parse a column using 
[`separate()`][G&W 2017, 12.4.1].

---

## Exercise 4
Both  [`separate()`][G&W 2017, 12.4.1]  and [`unite()`][G&W 2017, 12.4.2] have a
`remove` argument. What does it do? When does setting it to `FALSE` make sense?

***Exercise 4 Solution***
The `remove` argument removes input columns from the output data frame. It would make sense to set it to `FALSE` when it would be important to preserve the original data, or if the original data is useful separately or together in addition to combined. This could be the case if a unique identifier is the combination of several other variables.

**Note:** This question is based on [12.4.3 #2][G&W 2017, 12.4.3]. It is
designed to strengthen your ability to parse columns while making use of
arguments such as `remove`.

---

## Exercise 5
***Exercise 5 Solution included***
Using the [`who` dataset][G&W 2017, 12.6], calculate the total number of cases
of TB per year for China, India, and Bangladesh, then plot these statistics
over time. What country-year statistics, if any, surprise you?

**Hint:** Build on this code, which tidies `who`:

```{r, echo = TRUE, eval = TRUE}
who %>%
  gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(code = gsub("newrel", "new_rel", code)) %>%
  separate(code, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1) %>% 
  group_by(country, year) %>% 
  summarise(total_tb = sum(value)) %>% 
  filter(country %in% c('China', 'India', 'Bangladesh')) %>% 
  ggplot(aes(x = year, y = total_tb, color = country)) + geom_point() + geom_line()
```

**Note:** This question is based on [12.6.1 #4][G&W 2017, 12.6.1]. It is
designed to strengthen your ability to create a pipeline full of data wrangling
and visualization operations.

---

## Exercise 6
Begin by following these steps:
***Exercise 6 Solution included***
1. Join observations in `flights` with those in `weather` by `origin`, `year`,
`month`, `day`, and `hour`.  

```{r, echo = TRUE, eval = TRUE, warning = FALSE}
flight_weather <- inner_join(flights, weather, 
                            by = c("origin", "year", "month", "day", "hour"))
```

2. Bin `wind_gust` and calculate average `dep_delay` for each bin.  

```{r, echo = TRUE, eval = TRUE, warning = FALSE}
summary(flight_weather$wind_gust)

flight_weather <- flight_weather %>% 
  mutate(weather_bins = 
           cut(wind_gust, 
               breaks = seq(0, 
                            max(wind_gust, 
                                na.rm = TRUE), 
                            5))) %>% 
  group_by(weather_bins) %>% 
  summarise(dep_delay_bins = mean(dep_delay, na.rm = TRUE))
  
```

3. Create a bar graph.

```{r, echo = TRUE, eval = TRUE, warning = FALSE}
flight_weather %>% 
  ggplot(aes(weather_bins, dep_delay_bins)) +
    geom_col()
```


At what gust speeds are departure delays out of NYC the longest on average?

**Note:** This question is based on [13.4.6 #4][G&W 2017, 13.4.6]. It is
designed to strengthen your ability to merge and analyze relational data with
[`inner_join()`][G&W 2017, 13.4.2] and [`summarize()`][G&W 2017, 5.6].

[G&W 2017]: http://r4ds.had.co.nz/
[G&W 2017, 5.6]: http://r4ds.had.co.nz/transform.html#grouped-summaries-with-summarise
[G&W 2017, 12]: http://r4ds.had.co.nz/tidy-data.html
[G&W 2017, 12.3.1]: http://r4ds.had.co.nz/tidy-data.html#gathering
[G&W 2017, 12.3.2]: http://r4ds.had.co.nz/tidy-data.html#spreading
[G&W 2017, 12.3.3]: http://r4ds.had.co.nz/tidy-data.html#exercises-22
[G&W 2017, 12.4.1]: http://r4ds.had.co.nz/tidy-data.html#separate
[G&W 2017, 12.4.2]: http://r4ds.had.co.nz/tidy-data.html#unite
[G&W 2017, 12.4.3]: http://r4ds.had.co.nz/tidy-data.html#exercises-23
[G&W 2017, 12.6]: http://r4ds.had.co.nz/tidy-data.html#case-study
[G&W 2017, 12.6.1]: http://r4ds.had.co.nz/tidy-data.html#exercises-25
[G&W 2017, 13]: http://r4ds.had.co.nz/relational-data.html
[G&W 2017, 13.4.2]: http://r4ds.had.co.nz/relational-data.html#inner-join
[G&W 2017, 13.4.6]: http://r4ds.had.co.nz/relational-data.html#exercises-28